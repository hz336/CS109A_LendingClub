{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uaoVZSrv48aE"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j02kGLE-48ah"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Sampling\n",
    "We split training  and test dataset by stratifing on the loan grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv(\"data/df_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set: (1704488, 89)\n",
      "Shape of the training set: (426122, 89)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df_clean, \n",
    "                                     test_size = .2, \n",
    "                                     stratify = df_clean['grade'], \n",
    "                                     random_state=90)\n",
    "\n",
    "print(\"Shape of the training set: {}\".format(df_train.shape))\n",
    "print(\"Shape of the training set: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_columns(df, target_col, drop_columns):\n",
    "    # Get the response variable\n",
    "    y_train = df[[target_col]]\n",
    "\n",
    "    # Drop the required columns\n",
    "    X_train = df.drop(drop_columns, axis=1)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_columns(df_train, target_col='response', drop_columns=['response'])\n",
    "X_test, y_test = split_columns(df_test, target_col='response', drop_columns=['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "We standardize all the predictors that are not dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_datasets(train_data, test_data, cols_to_scale):\n",
    "    \"\"\"\n",
    "    This function will be used to standardize columns in your datasets. It\n",
    "    also allows you to pass in a test dataset, which will be standardized\n",
    "    using the stats from the training data. \n",
    "    \n",
    "    :param: train: The training dataset\n",
    "    :param: test: The test dataset, which will be standardized using stats \n",
    "                  from the training data. \n",
    "    :param: cols_to_scale: List containing the column names to be standardized\n",
    "    :return: (DataFrame, DataFrame) Standardized test and training DataFrames\n",
    "    \"\"\"\n",
    "    \n",
    "    train = train_data.copy()\n",
    "    test = test_data.copy()\n",
    "    \n",
    "    # Fit the scaler on the training data\n",
    "    scaler = StandardScaler().fit(train[cols_to_scale])\n",
    "\n",
    "    # Scale both the test and training data. \n",
    "    train[cols_to_scale] = scaler.transform(train[cols_to_scale])\n",
    "    test[cols_to_scale] = scaler.transform(test[cols_to_scale])\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = [\"loan_amnt\"                     \n",
    "                , \"term\"                          \n",
    "                , \"int_rate\"                      \n",
    "                , \"grade\"                         \n",
    "                , \"emp_length\"                    \n",
    "                , \"annual_inc\"                    \n",
    "                , \"dti\"                           \n",
    "                , \"delinq_2yrs\"                   \n",
    "                , \"earliest_cr_line\"              \n",
    "                , \"inq_last_6mths\"                \n",
    "                , \"open_acc\"                      \n",
    "                , \"pub_rec\"                       \n",
    "                , \"revol_util\"                                  \n",
    "                , \"acc_now_delinq\"                \n",
    "                , \"tot_coll_amt\"                  \n",
    "                , \"tot_cur_bal\"                                         \n",
    "                , \"fico\"] \n",
    "X_train, X_test = scale_datasets(X_train, X_test, cols_to_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Good and Bad Loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AddBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "day_level_test.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
