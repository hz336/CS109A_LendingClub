{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is especially important for financial dataset, which is very noisy in nature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j02kGLE-48ah"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = pd.read_csv(\"data/output_eda.csv\", parse_dates=['issue_d'])\n",
    "df_clean = df_eda.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Sample Bias\n",
    "As we have seen in the EDA - Good Loans vs Bad Loans part, most of loans in recent five years are all new loans with most of them as current status. However, as time goes by, some of the loans may become bad loans. In order to avoid this sample bias, we decide to drop loans with issue dates in recent five years.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['year'] < 2013]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Response Variable\n",
    "According the lending club website, we define the following loan status as <b>bad loans</b>: \n",
    "- <b>Default</b>: Loan has not been current for an extended period of time. \n",
    "- <b>Charged Off</b>: Loan for which there is no longer a reasonable expectation of further payments. Upon Charge Off, the remaining principal balance of the Note is deducted from the account balance. \n",
    "- <b>In Grace Period</b>: Loan is past due but within the 15-day grace period. \n",
    "- <b>Late (16-30)</b>: Loan has not been current for 16 to 30 days. \n",
    "- <b>Late (31-120)</b>: Loan has not been current for 31 to 120 days. \n",
    "- <b>Does not meet the credit policy. Status:Charged Off</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_loan = set([\"Charged Off\", \n",
    "            \"Default\", \n",
    "            \"Does not meet the credit policy. Status:Charged Off\", \n",
    "            \"In Grace Period\", \n",
    "            \"Late (16-30 days)\", \n",
    "            \"Late (31-120 days)\"])\n",
    "\n",
    "df_clean['response'] = df_clean['loan_status'].apply(lambda x: 1 if x in bad_loan else 0)\n",
    "df_clean.drop(['loan_status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing Value \n",
    "We replaced missing value with mean value in each loan grade bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the columns that are numeric without 100% coverage\n",
    "col_count = df_clean.describe().loc['count',]\n",
    "col_count_nrm = col_count / max(col_count)\n",
    "\n",
    "# Replace these columns with mean value in each loan grade\n",
    "col_missing = ['tot_cur_bal', 'tot_coll_amt', 'dti', 'inq_last_6mths']\n",
    "for col in col_missing: \n",
    "    df_clean[col] = df_clean.groupby(\"grade\")[col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Dates\n",
    "Some features of types of dates could be helpful to predict the loan default probability, such as <b>earliest credit line date</b> for the applicant. Typically the longer the history of the applicant's credit line, the more confidence we have on his/her FICO score, and the lower probability of default in general. However, we need to anchor the earliest credit line date relative to the loan issue date, as that's the information we know at initial investment stage.  \n",
    "\n",
    "We also cleaned up other date columns that should not be treated as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['earliest_cr_line'] = pd.to_datetime(df_clean['earliest_cr_line'])\n",
    "df_clean['earliest_cr_line'] = df_clean['issue_d'] - df_clean['earliest_cr_line']\n",
    "df_clean['earliest_cr_line'] = df_clean['earliest_cr_line'].apply(lambda x: x.days)\n",
    "df_clean.drop(['issue_d'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Categorical Variables\n",
    "There are two types of categorical variables that we need to engineer. \n",
    "- One type of categorical features contain ordinal order, and we want to maitain that order, like grade (In term of loan quality, A > B > ... > G), and employement length (10+ years > 9 years > ... > 1 year). \n",
    "- The other type of cateorical features don't have any ordinal order, like purpose of the loan, application type, etc. We will use one-hot-encoding to create dummy variables for this type of categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop States \n",
    "df_clean.drop(['addr_state'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan grade\n",
    "grade_map = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7}\n",
    "df_clean['grade'] = df_clean['grade'].map(grade_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employement Length\n",
    "df_clean['emp_length'] = df_clean['emp_length'].apply(lambda x: '0 year' if x == '< 1 year' else x)\n",
    "\n",
    "# Extract numerical value\n",
    "import re\n",
    "df_clean['emp_length'] = df_clean['emp_length'].apply(lambda x: int(re.findall(r'\\d+', x)[0]) \n",
    "                                                    if isinstance(x, str) else np.nan)\n",
    "\n",
    "# Replace missing employment length as mean value in each sub_grade bucket\n",
    "df_clean['emp_length'] = df_clean.groupby(\"grade\")['emp_length'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Type\n",
    "application_type_map = {'Individual': 1, 'Joint App': 0}\n",
    "df_clean['application_type'] = df_clean['application_type'].map(application_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification Status\n",
    "df_clean.rename({'verification_status': 'ver'}, axis=1, inplace=True)\n",
    "\n",
    "ver_map = {\n",
    "    \"Source Verified\": \"Source_Verified\",\n",
    "    \"Not Verified\": \"Not_Verified\",\n",
    "    \"Verified\": \"Verified\"\n",
    "}\n",
    "df_clean['ver'] = df_clean['ver'].map(ver_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding\n",
    "dummy_list = ['home_ownership', 'ver', 'purpose']\n",
    "df_clean = pd.get_dummies(df_clean, columns=dummy_list, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Polynomial Terms \n",
    "There might be non-linear effects between the response variable and the predictors, and thus we added polynomial and interaction terms to some of the important non-binary features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.reset_index(inplace=True, drop=True)\n",
    "\n",
    "poly_vars = ['int_rate', 'annual_inc', 'revol_util', 'term', 'dti', 'loan_amnt', 'earliest_cr_line', 'grade']\n",
    "df_poly = df_clean[poly_vars]\n",
    "\n",
    "tra = PolynomialFeatures(degree=3, include_bias=False)\n",
    "temp = tra.fit_transform(df_poly)\n",
    "df_temp = pd.DataFrame(temp, columns=tra.get_feature_names(df_poly.columns))\n",
    "\n",
    "df_clean.drop(poly_vars, axis=1, inplace=True)\n",
    "df_clean = df_clean.merge(df_temp, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Additional Features\n",
    "We generated an addtional feature that we believe would be helpful. \n",
    "- The range of FICO score (fico_rng): (High FICO - Low FICO) / Mean FICO. This feature is designed to capture the range of FICO score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['fico_rng'] = (df_clean['fico_range_high'] - df_clean['fico_range_low']) / df_clean['fico']\n",
    "df_clean.drop(['fico_range_low', 'fico_range_high'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_clean[pd.isnull(df_clean).any(axis=1)].shape[0] == 0, \"Some rows have missing value!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dataset\n",
    "df_clean.to_csv(\"data/output_fe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "day_level_test.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
